var documenterSearchIndex = {"docs":
[{"location":"#FluxSegmentationModels","page":"Home","title":"FluxSegmentationModels","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for FluxSegmentationModels.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"#FluxSegmentationModels.EncoderConfig","page":"Home","title":"FluxSegmentationModels.EncoderConfig","text":"EncoderConfig\n\nSuper type of all encoder models. The type parameter F denotes the number of features produced by each block of the encoder.\n\nExample Implementation\n\nstruct ResNet <: EncoderConfig\n    depth::Int\n    pretrain::Bool\nend\n\nfunction ResNet(;depth=50, pretrain=true)\n    @argcheck depth in (18,34,50,101,152)\n    return ResNet(depth, pretrain)\nend\n\nfunction encoder_features(e::ResNet)\n    @match e.depth begin\n        18 || 34 => [EncoderFeature(64,4), EncoderFeature(128,8), EncoderFeature(256,16), EncoderFeature(512,32)]\n        50 || 101 || 152 => [EncoderFeature(256,4), EncoderFeature(512,8), EncoderFeature(1024,16), EncoderFeature(2048,32)]\n    end\nend\n\nfunction build_encoder(e::ResNet; inchannels=3)\n    resnet = _build_resnet(e.depth, inchannels, e.pretrain)\n    Flux.Chain(\n        Flux.Chain(resnet[1]..., resnet[2]...),\n        resnet[3],\n        resnet[4],\n        resnet[5],\n    )\nend\n\nfunction _build_resnet(depth::Int, inchannels::Int, pretrain::Bool)\n    return Metalhead.ResNet(depth; inchannels, pretrain).layers[1]\nend\n\n\n\n\n\n","category":"type"},{"location":"#FluxSegmentationModels.Conv-Tuple{Tuple{Int64, Int64}, Int64, Int64}","page":"Home","title":"FluxSegmentationModels.Conv","text":"Conv(kernel_size::Tuple{Int,Int}, in::Int, out::Int; act=Flux.relu, norm=:BN, groups=1, dilation=1)\n\nA block of convolutional layers with optional batch normalization.\n\nParameters\n\nkernel_size: The size of the filter to use for each layer.\nin: The number of input features.\nout: The number of output features.\nact: The activation function to apply after each convolution.\nnorm: Specifies the type of layer normalization. One of :BN, :LN, or nothing.\ngroup: The number of groups to divide the convolution into.\ndilation: The dilation rate for the kernel.\n\n\n\n\n\n","category":"method"},{"location":"#FluxSegmentationModels.ConvBlock-Tuple{Tuple{Int64, Int64}, Int64, Int64}","page":"Home","title":"FluxSegmentationModels.ConvBlock","text":"ConvBlock(kernel_size::Tuple{Int,Int}, in::Int, out::Int; act=Flux.relu, depth=2, norm=:BN)\n\nA block of convolutional layers with optional batch normalization.\n\nParameters\n\nkernel_size: The size of the filter to use for each layer.\nin: The number of input features.\nout: The number of output features.\nact: The activation function to apply after each convolution.\ndepth: The number of successive convolutions in the block.\nnorm: Specifies the type of layer normalization. One of :BN, :LN, or nothing\n\n\n\n\n\n","category":"method"},{"location":"#FluxSegmentationModels.FPNDecoder-Tuple{AbstractVector{<:Integer}, AbstractVector{<:Integer}}","page":"Home","title":"FluxSegmentationModels.FPNDecoder","text":"FPNDecoder(encoder_dims::AbstractVector{<:Integer}, encoder_scales::AbstractVector{<:Integer}; embed_dim=256, dropout=0.0, batch_norm=true)\n\nA MLP-style decoder as used in SegFormer. Expects a tuple of block-wise activations as input.\n\nParameters\n\nencoder_dims: The feature dimension of each encoder block output ordered from first to last.\nencoder_scales: The scale of each encoder block output with respect to the input ordered from first to last.\nembed_dim: The size of the embedding dimension to use. Shared by all layers.\ndropout: The dropout probability to use after the last layer.\nbatch_norm: Use batch normalization after each convolution.\n\n\n\n\n\n","category":"method"},{"location":"#FluxSegmentationModels.SegFormerDecoder-Tuple{AbstractVector{<:Integer}, AbstractVector{<:Integer}}","page":"Home","title":"FluxSegmentationModels.SegFormerDecoder","text":"SegFormerDecoder(feature_dims::Vector{Int}, feature_scales::Vector{Int}; embed_dim=768, dropout=0.0, norm=:BN)\n\nA MLP-style decoder as used in SegFormer. Expects a tuple of block-wise activations as input.\n\nParameters\n\nencoder_dims: The feature dimension of each encoder block output ordered from first to last.\nencoder_scales: The scale of each encoder block output with respect to the input ordered from first to last.\nembed_dim: The size of the embedding dimension to use. Shared by all layers.\ndropout: The dropout probability to use after the last layer.\nnorm: One of either :BN or :LN.\n\n\n\n\n\n","category":"method"},{"location":"#FluxSegmentationModels.SeparableConv-Tuple{Tuple{Int64, Int64}, Int64, Int64}","page":"Home","title":"FluxSegmentationModels.SeparableConv","text":"SeparableConv(kernel::Tuple{Int,Int}, in::Int, out::Int; stride=1, act=identity, pad=Flux.SamePad(), norm=:BN)\n\nA block of convolutional layers with optional batch normalization.\n\nParameters\n\nkernel_size: The size of the filter to use for each layer.\nin: The number of input features.\nout: The number of output features.\nstride: The stride of the convolution operation.\nact: The activation function to apply after each convolution.\nnorm: Specifies the type of layer normalization. One of :BN, :LN, or nothing.\n\n\n\n\n\n","category":"method"},{"location":"#FluxSegmentationModels.UNetDecoder-Tuple{AbstractVector{<:Integer}, AbstractVector{<:Integer}}","page":"Home","title":"FluxSegmentationModels.UNetDecoder","text":"UNetDecoder(encoder_dims, encoder_scales; decoder_dims=[64,128,256,512], batch_norm=true)\n\nConstruct a U-Net style decoder that expects a tuple of WHCN arrays corresponding to the output of each block of a matching encoder.\n\nParameters\n\nencoder_dims: The feature dimension of each encoder block output ordered from first to last.\nencoder_scales: The scale of each encoder block output with respect to the input ordered from first to last.\ndecoder_dims: The feature dimension of each decoder block ordered from top to bottom.\nbatch_norm: If true, a batch norm operation will be applied after each convolution in the decoder.\n\n\n\n\n\n","category":"method"},{"location":"#FluxSegmentationModels.Upsample-Tuple{Int64}","page":"Home","title":"FluxSegmentationModels.Upsample","text":"Upsample(factor::Int; method=:nearest)\n\nConstruct a layer that takes an image with shape WHCN and upsamples it by factor.\n\nParameters\n\nfactor: The factor by which to upscale the input image.\nmethod: The type of resampling to use; must be one of :nearest or :bilinear.\n\n\n\n\n\n","category":"method"},{"location":"#FluxSegmentationModels.build_encoder","page":"Home","title":"FluxSegmentationModels.build_encoder","text":"build_encoder(encoder::EncoderConfig)\n\nConstructs an encoder model based on the provided EncoderConfig configuration.\n\nParameters\n\nencoder: An EncoderConfig object specifying the architecture and configuration of the encoder to be built.\n\nReturns\n\nA standard Flux.Chain layer containing each block of the encoder. The returned encoder is ready to be integrated into more complex architectures like U-Net or used as a standalone feature extractor.\n\nExample\n\nencoder = build_encoder(ResNet(depth=50, pretrain=true))\n\n\n\n\n\n","category":"function"},{"location":"#FluxSegmentationModels.encoder_features","page":"Home","title":"FluxSegmentationModels.encoder_features","text":"encoder_features(encoder::EncoderConfig)\n\nReturns the dimension and scale of the provided encoder.\n\n\n\n\n\n","category":"function"}]
}
